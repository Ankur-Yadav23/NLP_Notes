{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KHdsby19C-e"
      },
      "source": [
        "NATURAL LANGUAGE PROCESSING "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BVq8knTM9GTP"
      },
      "outputs": [],
      "source": [
        "# TOKENIZATION - THE PROCESS OF CONVERTING SENTENCE OR PARAGRAPH INTO WORDS OR TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "121JWAn79MI7",
        "outputId": "8ac381b0-fe8d-457b-d448-a1ce25db20a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\vy788\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AI', 'is', 'coined', 'in', 'the', 'year', 'but', 'it', 'gained', 'popularity', 'recently']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Word tokenize\n",
        "\n",
        "text = 'AI is coined in the year but it gained  popularity recently'\n",
        "\n",
        "print(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lNkeCv_9RiN",
        "outputId": "2f287516-d77e-4c35-ee94-137f24d76b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AI is coined in the year, but it gained  popularity recently']\n"
          ]
        }
      ],
      "source": [
        "# Sentence tokenize\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = 'AI is coined in the year, but it gained  popularity recently'\n",
        "\n",
        "print(sent_tokenize(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgVXAOU092Xb"
      },
      "source": [
        "**STEMMING** - THE PROCESS OF CONVERTING WORDS INTO ROOT WORDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtoqvREY9w5X",
        "outputId": "2b0affc7-4602-4dd5-dbda-67fe49eda35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wait\n",
            "wait\n",
            "wait\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "words = ['wait','waiting','waited']\n",
        "\n",
        "\n",
        "s = PorterStemmer()\n",
        "\n",
        "for w in words:\n",
        "  root_word = s.stem(w)\n",
        "  print(root_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7YNSsjh-b3Z"
      },
      "source": [
        "**LEMMITIZAION** - the process of cutting the suffix from the word, it perform morphological analysis of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V13if4ZX-VNJ",
        "outputId": "416a44e9-10d4-43d9-f2c0-f49956fe575a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\vy788\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\vy788\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4APqjTSO-qOs",
        "outputId": "17fb57e5-72df-4886-a3c1-3af87efab4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "study\n",
            "cry\n",
            "waited\n"
          ]
        }
      ],
      "source": [
        "words = ['studies','cries','waited']\n",
        "\n",
        "\n",
        "s = WordNetLemmatizer()\n",
        "\n",
        "for w in words:\n",
        "  root_word = s.lemmatize(w)\n",
        "  print(root_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lr0bbVh_ogU"
      },
      "source": [
        "**STOPWORDS** - the unneccesary or repeated words in the corpus like 'the','from','a'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53zcMqLw_oAA",
        "outputId": "b9848ee1-041c-41a0-ee22-30b4452124c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\vy788\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE6j04rR-5YR",
        "outputId": "487c2dbf-cc7d-4e67-b72f-986c2b2c49bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ai', 'introduced', 'year', '1956']\n"
          ]
        }
      ],
      "source": [
        "data = 'ai was introduced in the year 1956'\n",
        "stopwords = set(stopwords.words('english'))\n",
        "words = word_tokenize(data)\n",
        "wordsFiltered = []\n",
        "\n",
        "for w in words:\n",
        "  if w not in stopwords:\n",
        "    wordsFiltered.append(w)\n",
        "\n",
        "print(wordsFiltered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQuZgQKSA3jW"
      },
      "source": [
        "**BAG OF WORDS** -  The process of converting words into vectors - how many times the words occured in the sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "zK1ufN7kA-Ql",
        "outputId": "1f1cfc8c-c60e-411b-8317-e730b2e6f4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   great  india  is  love  we\n",
            "0      0      1   0     1   1\n",
            "1      1      1   1     0   0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Define the text content as a list of strings (each line is a separate document).\n",
        "content = [\"we love india.\", \"india is great\"]\n",
        "\n",
        "# Initialize the CountVectorizer.\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# Fit and transform the content into a bag of words matrix.\n",
        "bag = cv.fit_transform(content)\n",
        "\n",
        "# Convert the bag of words matrix to a Pandas DataFrame for better visualization.\n",
        "df = pd.DataFrame(bag.toarray(), columns=cv.get_feature_names_out())\n",
        "\n",
        "# Print the resulting DataFrame with word counts.\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRGyf6NYCJWA"
      },
      "source": [
        "**Collacations** - the pair of words occured together in the documents\n",
        "\n",
        "\n",
        "types \n",
        "1. Bigram - combination of two words\n",
        "2. trigram - combination of three words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDWdxnSCLhY",
        "outputId": "abe959d0-81aa-4d79-a513-206f9819683f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(('AI', 'is'), ('is', 'coined'), ('coined', 'in'), ('in', 'the'), ('the', 'year'), ('year', ','), (',', 'but'), ('but', 'it'), ('it', 'gained'), ('gained', 'popularity'), ('popularity', 'recently'))\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "output = tuple(nltk.bigrams(tokens))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jqhEeG6CvAj",
        "outputId": "b3ad2990-a2a2-48db-91dc-60983f864dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(('AI', 'is', 'coined'), ('is', 'coined', 'in'), ('coined', 'in', 'the'), ('in', 'the', 'year'), ('the', 'year', ','), ('year', ',', 'but'), (',', 'but', 'it'), ('but', 'it', 'gained'), ('it', 'gained', 'popularity'), ('gained', 'popularity', 'recently'))\n"
          ]
        }
      ],
      "source": [
        "tokens = nltk.word_tokenize(text)\n",
        "output = tuple(nltk.trigrams(tokens))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "ZbMh3OsQDAlB",
        "outputId": "abb85ee6-8e65-4510-e1ec-7f537b29caa1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>great</th>\n",
              "      <th>india</th>\n",
              "      <th>india is</th>\n",
              "      <th>is</th>\n",
              "      <th>is great</th>\n",
              "      <th>love</th>\n",
              "      <th>love india</th>\n",
              "      <th>we</th>\n",
              "      <th>we love</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   great  india  india is  is  is great  love  love india  we  we love\n",
              "0      0      1         0   0         0     1           1   1        1\n",
              "1      1      1         1   1         1     0           0   0        0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "content = \"\"\"we love india.\n",
        "india is great\"\"\"\n",
        "\n",
        "cv = CountVectorizer(ngram_range = (1,2))\n",
        "\n",
        "bag = cv.fit_transform(content.splitlines())\n",
        "\n",
        "pd.DataFrame(bag.toarray(),columns = cv.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjyBadlDZfx"
      },
      "source": [
        "**TFIDF** - the process of converting words into vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Vr2jx6FeDHY8",
        "outputId": "7a0af8d4-0732-401a-aaab-ee51602a28be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      great     india        is      love        we\n",
            "0  0.000000  0.449436  0.000000  0.631667  0.631667\n",
            "1  0.631667  0.449436  0.631667  0.000000  0.000000\n"
          ]
        }
      ],
      "source": [
        "# TfidfVectorizer to convert a collection of text documents into a matrix of TF-IDF (Term Frequency-Inverse Document Frequency) values.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Define the text content as a multi-line string.\n",
        "content = \"\"\"we love india.\n",
        "india is great\"\"\"\n",
        "\n",
        "# Initialize the TfidfVectorizer.\n",
        "cv = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the content into a TF-IDF matrix.\n",
        "bag = cv.fit_transform(content.splitlines())\n",
        "\n",
        "# Convert the TF-IDF matrix to a Pandas DataFrame for better visualization.\n",
        "# The bag.toarray() method converts the sparse matrix to a dense array.\n",
        "# The column names are obtained using cv.get_feature_names_out().\n",
        "df = pd.DataFrame(bag.toarray(), columns=cv.get_feature_names_out())\n",
        "\n",
        "# Print the resulting DataFrame with TF-IDF values.\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "GbVtO-cKDZDS",
        "outputId": "e6d2a1b7-ef35-47e3-ab34-962f24f3d90a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>great</th>\n",
              "      <th>india</th>\n",
              "      <th>india is</th>\n",
              "      <th>is</th>\n",
              "      <th>is great</th>\n",
              "      <th>love</th>\n",
              "      <th>love india</th>\n",
              "      <th>we</th>\n",
              "      <th>we love</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.335176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.471078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.335176</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.471078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      great     india  india is        is  is great      love  love india  \\\n",
              "0  0.000000  0.335176  0.000000  0.000000  0.000000  0.471078    0.471078   \n",
              "1  0.471078  0.335176  0.471078  0.471078  0.471078  0.000000    0.000000   \n",
              "\n",
              "         we   we love  \n",
              "0  0.471078  0.471078  \n",
              "1  0.000000  0.000000  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content = \"\"\"we love india.\n",
        "india is great\"\"\"\n",
        "\n",
        "cv = TfidfVectorizer(ngram_range = (1,2))\n",
        "\n",
        "bag = cv.fit_transform(content.splitlines())\n",
        "\n",
        "pd.DataFrame(bag.toarray(),columns = cv.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGfqLXceDyk6"
      },
      "outputs": [],
      "source": [
        "# Term Frequency (TF):\n",
        "\n",
        "# Term Frequency measures how frequently a term (word) appears in a document.\n",
        "# It is a local measure, meaning it focuses on a specific document.\n",
        "# The formula for Term Frequency is often given as:\n",
        "# scss\n",
        "# Copy code\n",
        "# TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in document d)\n",
        "# It calculates the importance of a term within a document by considering how often that term occurs in that document.\n",
        "\n",
        "# Inverse Document Frequency (IDF):\n",
        "\n",
        "# Inverse Document Frequency measures how important a term is within the entire collection of documents (corpus).\n",
        "# It is a global measure, meaning it considers the entire document collection.\n",
        "# The formula for Inverse Document Frequency is often given as:\n",
        "# scss\n",
        "# Copy code\n",
        "# IDF(t) = log_e(Total number of documents / Number of documents containing term t)\n",
        "# It calculates the importance of a term by assessing how unique or rare it is across the entire corpus. Terms that appear in many documents have a low IDF value, while terms that appear in only a few documents have a high IDF value.\n",
        "\n",
        "# The TF-IDF value for a term in a specific document is obtained by multiplying its Term Frequency (TF) with its Inverse Document Frequency (IDF):\n",
        "\n",
        "# scss\n",
        "# Copy code\n",
        "# TF-IDF(t, d) = TF(t, d) * IDF(t)\n",
        "# The resulting TF-IDF score reflects the importance of a term within a document relative to the entire corpus. Terms that are common within the document but rare in the corpus will have higher TF-IDF scores, indicating their significance in that particular document."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
